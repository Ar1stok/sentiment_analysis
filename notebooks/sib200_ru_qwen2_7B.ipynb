{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB24GA6Ktsiy"
      },
      "source": [
        "## Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EaBWpVyuDTq"
      },
      "source": [
        "- Analyze text classification using LLM Qwen2-7B-Instruct\n",
        "- generate a classification_report with metrics\n",
        "- measure the retrieval time of LLM and logreg predictions\n",
        "- compare LLM and logreg metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6PMGeWYwqcC"
      },
      "source": [
        "https://huggingface.co/Qwen/Qwen2-7B-Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dMQe0BAfPmv",
        "outputId": "c98402cf-b13e-4bbe-9113-29d8572252a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
            "Requirement already satisfied: Levenshtein==0.27.1 in /usr/local/lib/python3.11/dist-packages (from python-Levenshtein) (0.27.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\n"
          ]
        }
      ],
      "source": [
        "# install required libraries\n",
        "!pip install fuzzywuzzy\n",
        "!pip install -U datasets fsspec\n",
        "!pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WopE6roEOakC"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Union, List\n",
        "from datasets import load_dataset\n",
        "from fuzzywuzzy import fuzz, process\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRw4a3fwQUsk"
      },
      "outputs": [],
      "source": [
        "# function for selecting the prompt for llm\n",
        "def prepare_message_for_llm(text: Union[str, List[str]], categories: List[str]) -> Dict[str, Union[List[Dict[str, str]], List[List[Dict[str, str]]]]]:\n",
        "    if isinstance(text, str):\n",
        "        text = [text]\n",
        "\n",
        "    messages = []\n",
        "\n",
        "    for msg in text:\n",
        "        messages.append([{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Прочтите текст и определите, какая тема из списка наиболее представлена в следующем тексте. Текст: {msg} В качестве ответа напишите только название темы из списка, больше ничего: {', '.join(categories)}.\"\n",
        "        }])\n",
        "\n",
        "    return {'message_for_llm': messages}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimental examples\n",
        "messages = [[{'role': 'user', 'content': 'Прочтите текст и определите, какая тема из списка наиболее представлена в следующем тексте. Текст: Если увеличить расстояние для бега с четверти до половины мили, скорость становится не так важна, тогда как выносливость превращается в абсолютную необходимость. В качестве ответа напишите только название темы из списка, больше ничего: entertainment, geography, health, politics, science/technology, sports, travel.'}],\n",
        "            [{'role': 'user', 'content': 'Прочтите текст и определите, какая тема из списка наиболее представлена в следующем тексте. Текст: Посмотрите, какие поездки рекламирует агент, на сайте или на витрине офиса. В качестве ответа напишите только название темы из списка, больше ничего: entertainment, geography, health, politics, science/technology, sports, travel.'}],\n",
        "            [{'role': 'user', 'content': 'Прочтите текст и определите, какая тема из списка наиболее представлена в следующем тексте. Текст: Население Ватикана составляет около 800 человек. Это самая маленькая независимая страна в мире, а также страна, имеющая наименьшее население. В качестве ответа напишите только название темы из списка, больше ничего: entertainment, geography, health, politics, science/technology, sports, travel.'}],]"
      ],
      "metadata": {
        "id": "WVG0IIBjnIpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "76171159519644ff88f5e31fc4664888",
            "35b156433f454934b2c3b0b5e2048cb4",
            "df3a089f6aab47458a0d97845f8b97f5",
            "11d6a13a39f9445ea85d09d5664d8709",
            "11baac0e41ef46bd8efca0afb92addf7",
            "85fcfcf220b1406c865eaf1f53007b60",
            "d8db99ceaacc44b093d2d2c28beafd77",
            "2a35cb8fc1e144cf9e260d7c4c91539d",
            "89df318fde414b21ad6f0d21f4dc45ee",
            "adf1eab597c246dead13f34a6106dcfc",
            "717b99d188004d7a8a8ef577c7f5e37f"
          ]
        },
        "id": "Lahzgx7mJDXx",
        "outputId": "8fb640d3-9a6a-47f3-a1bc-0648467a08d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76171159519644ff88f5e31fc4664888"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# load model Qwen/Qwen2-7B-Instruct\n",
        "device = 'cuda'\n",
        "\n",
        "llm = pipeline(\"text-generation\", model=\"Qwen/Qwen2-7B-Instruct\", return_full_text=False,\n",
        "                max_new_tokens=256, device_map='auto', torch_dtype='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484,
          "referenced_widgets": [
            "384153d6ad86414b96f3d357c2437521",
            "d02e9c99e80440f68319aa80818a734a",
            "f1b9b42ec696443dabd394494158c9ee",
            "bb653c21d83249dd99be71e26170d713",
            "26d2b1041260410286d49d0cfcf763e7",
            "bc16699dda95471fbfc2af8e6645c0e8",
            "64cdcc67cbc64887b15fb3b42a13aa16",
            "08032b113bff494d8655263661c17564",
            "d03e139e7c264c228454af3009483140",
            "966ee32da4404172be8aab3729f63ae6",
            "17b244a0ab5d47969f984dffc534c5ad",
            "4727120d6df549fcae784f4ba7f371bf",
            "6921580a5fad4d2ab9a823a26b489c95",
            "f41ddcf23fc54256aae1f5a6aa70eb9c",
            "a813bc1f178c4466974bbff6e1ba76d3",
            "b680b6ea8874468a8bf2a1fa98a14dc7",
            "7c5313709c7b4c16be1ac179cf4b079d",
            "4bb39e3c79784bd686e80dac65caaafa",
            "f6e8773b93054eea9ad17c1b9b9aedd7",
            "722057f192a34f54a656ef8da8fd4c5a",
            "22f770cc6cb6443bb4f9da7eb309d5d2",
            "4623546e947644448e62393171339bbc",
            "2b1bef5f09e54e7b836c15cad0436bdc",
            "8d871899d3894376affb99c7c126e111",
            "39ce79fa873041ffb0eb7f62687dbb3e",
            "f3dee94e3c454b9d9e6115174bde7b8b",
            "eb35608746f74ca1b37872e39404e77d",
            "5b7cb3c474624910b9234d1848969e2c",
            "59edd297bc6e44c0aab1edbf1cc83406",
            "c2992f6950f5453fb86644b1f758024a",
            "ef2047c1c4e04af1811238d2cc9b1bc6",
            "7e58631544c6412186db3924e1f903db",
            "3047fa0faf2f4f93ae8ed0b2a54b8574",
            "2d42b67aa90440dc81239e521d68b569",
            "f29cd34e25f846bc81b7984c32b10d6c",
            "a8480de63f01462091894621862acc0f",
            "007ec04dfe4e4752b22ac3df740ae609",
            "0c2b0b46b5d9488ebef00a5f7e02d305",
            "7d9eb22e33654d05b36f8b1acfd20a25",
            "c3100f71d84e4103945c25e2c4ca6ba5",
            "f6ec766c4902410c9fa0d3aa39a5a3e0",
            "bd1e9f85a65b464a9f3861227c2a3b45",
            "248ececb8f654def9355ef4a747f3220",
            "91710a1f97a148e494582eda7ab9a20c",
            "5d5fe79c4fd84f3fb3d57eb68f2d5fe9",
            "df7c4d012979454c929d2855dd3b658e",
            "fca4fceebe38405696fb99c0594074f6",
            "165cb4de0ec54bd28141527ece3337a4",
            "b5fedadd6f7643599bffc8f5590508a0",
            "5bb2ef47d8f94d2199ea249f7d4e2a18",
            "703af9b054264bc3a9150c4f5c9562c0",
            "ef500e486f7e46319106a39d4bdcc6ea",
            "03f638ea7a554c3ca8a9326db38fbf92",
            "314b1e3b7b0740afa49a9245c2e5c578",
            "9e20ff5420c7413da9e5c8b55b6e5848",
            "623b2e0acc4444f1a65fd0119a234d6f",
            "833269bc244c493d90b4fb4b48959d74",
            "88b1fc823ec94295b7235114d6ee6b1c",
            "f58fffcb19264ffab7c64e5439bfe879",
            "1133408c94ad456c9c6582baaa0ecf02",
            "a9b3eca5b5b14b1c97274f7f5a2df1e7",
            "05f1ff79e8454c9aa1c2e78c01f2bb66",
            "6ead9352f31647b48d18225baf39f80b",
            "e0f061c9ecd148d5a448d5e3182ba00d",
            "232007965dd9401eb20a6134ca014223",
            "ca22fb9fd2b54bbb8749b41754aaf307",
            "4f0cc5e786b24688bbb9a1156c5afa24",
            "d8df631136244a25a9615781f6921d82",
            "a8a591ac4483412db2d300bb7c1ea123",
            "b15ada8bf1b54aa5948568a3e8eca982",
            "04906f9d567e4a1393a3c5a6c59aafc8",
            "ff064b1a04d44d6fb2021f646bdb3983",
            "9c56e29e58ce422f8499dc174fab8c85",
            "9a19145a6e0240a0bf83d9b9b8f69d6c",
            "fa382195c3fb4dd5b561c74e6d666257",
            "6a2154b9481944f3ad32a0083709fa9a",
            "f6ef4f79452442afacfa91001c1efae5"
          ]
        },
        "id": "7gfMjzLZPtuy",
        "outputId": "6c580c1b-86eb-4dd0-8e0f-6461bd7765cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/47.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "384153d6ad86414b96f3d357c2437521"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.tsv:   0%|          | 0.00/195k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4727120d6df549fcae784f4ba7f371bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dev.tsv:   0%|          | 0.00/25.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b1bef5f09e54e7b836c15cad0436bdc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.tsv:   0%|          | 0.00/57.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d42b67aa90440dc81239e521d68b569"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d5fe79c4fd84f3fb3d57eb68f2d5fe9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "623b2e0acc4444f1a65fd0119a234d6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f0cc5e786b24688bbb9a1156c5afa24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['index_id', 'category', 'text'],\n",
              "        num_rows: 701\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['index_id', 'category', 'text'],\n",
              "        num_rows: 99\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['index_id', 'category', 'text'],\n",
              "        num_rows: 204\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# loading of dataset by train, validation, test samples\n",
        "dataset = load_dataset(\"Davlan/sib200\", \"rus_Cyrl\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "850ed348f4d4487b9e208caaf033fabe",
            "f17c315a76d849b09d3e4f96b52fc0a9",
            "c9fbb590bd9148dd826b0212e312bfd8",
            "95807b5f2ef34d6a916593edd3dd9ed4",
            "ffa60473238e4441ab96f1fce032c682",
            "484b13ff556c42be960e2251d7081d12",
            "dfbbb1fa831941a4aef572bce7ef8990",
            "873f1faf51e54a4e8faa0856a39af7e7",
            "e76d259a7f9045da845e7d86a105deca",
            "58f97cba89294602adf46b21eeefc50f",
            "834cb9f6306b44539701a8aa847fd7dc",
            "d12b248d5f594dc6a8628c3dfb8f4218",
            "83c95796ab3248d281986be040050b9a",
            "1ad2ba01c26b4869bd894f31b27f69f3",
            "33ac76d4ea4c4f28966cf359668c7ca6",
            "ba71a1cdbd534831b30be502a09c3a39",
            "a9639bd4cd2046ae801f0a5dfd54aee7",
            "8651f7d875de47d995a96566ef8cd6a3",
            "6e1de3f66c29492dbb2646a5094ffe17",
            "d53c0aba9ac74586baecb6d38c2e0c4e",
            "3fd84eb48c5b496aa5dbf86770d0d844",
            "fa7c3c309da7442aad5eec8ab95ebb56",
            "db645b32900e4069ac1a8734ab31de71",
            "4cab667c818a492fb8162ce507705197",
            "4a7eecfe78ad4faa860b7c47144754c0",
            "6210aa1f5aa0451ab5306ad037e56fbe",
            "6272342c88e048bbb8e109cac781c7d5",
            "9fe41a955f594f3aaadbce5481c07b72",
            "3aea6d1d546a4c99bf6cec53c62bb20c",
            "0c5ba8b9c1164bc5a05cf189aa02f07d",
            "7884e44aa8b44398ab887d8099221601",
            "e7f6e8e2ad264fde8858c2063d609725",
            "accaa2e5356b464aaddaefce9f2ddf7b"
          ]
        },
        "id": "xDPzGngNVP4S",
        "outputId": "dac9854f-adc9-4d74-ab1a-e4fbbebad099"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting to class labels:   0%|          | 0/701 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "850ed348f4d4487b9e208caaf033fabe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting to class labels:   0%|          | 0/99 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d12b248d5f594dc6a8628c3dfb8f4218"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting to class labels:   0%|          | 0/204 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db645b32900e4069ac1a8734ab31de71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['entertainment',\n",
              " 'geography',\n",
              " 'health',\n",
              " 'politics',\n",
              " 'science/technology',\n",
              " 'sports',\n",
              " 'travel']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# list of all categories from all samples\n",
        "dataset['train'] = dataset['train'].class_encode_column('category')\n",
        "dataset['validation'] = dataset['validation'].class_encode_column('category')\n",
        "dataset['test'] = dataset['test'].class_encode_column('category')\n",
        "\n",
        "categories = dataset['validation'].features['category'].names\n",
        "categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ2ici-ZVLxI"
      },
      "outputs": [],
      "source": [
        "# add the ‘message_for_llm’ column to the list of features, which will result from applying the prepare_message_for_llm function to texts\n",
        "dataset['train'] = dataset['train'].add_column(name=\"message_for_llm\", column=prepare_message_for_llm(dataset['train']['text'], categories)['message_for_llm'])\n",
        "dataset['validation'] = dataset['validation'].add_column(name=\"message_for_llm\", column=prepare_message_for_llm(dataset['validation']['text'], categories)['message_for_llm'])\n",
        "dataset['test'] = dataset['test'].add_column(name=\"message_for_llm\", column=prepare_message_for_llm(dataset['test']['text'], categories)['message_for_llm'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "guO192bVcht6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5267d52-2a33-4842-fcea-522eca6f40d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['index_id', 'category', 'text', 'message_for_llm'],\n",
              "        num_rows: 701\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['index_id', 'category', 'text', 'message_for_llm'],\n",
              "        num_rows: 99\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['index_id', 'category', 'text', 'message_for_llm'],\n",
              "        num_rows: 204\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "ZNALO_RCcjUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_val = list(map(lambda x: llm(x)[0]['generated_text'], dataset['validation']['message_for_llm']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fwa2MHipK5N",
        "outputId": "843fb6aa-c376-4215-c455-c754a50a0e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL16cbq2Z7M5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b76a62-0c0c-4b3b-ad8b-bf8f40786b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.67      0.75         9\n",
            "           1       0.78      0.88      0.82         8\n",
            "           2       0.90      0.82      0.86        11\n",
            "           3       0.93      0.93      0.93        14\n",
            "           4       0.89      0.96      0.92        25\n",
            "           5       0.92      0.92      0.92        12\n",
            "           6       0.80      0.80      0.80        20\n",
            "\n",
            "    accuracy                           0.87        99\n",
            "   macro avg       0.87      0.85      0.86        99\n",
            "weighted avg       0.87      0.87      0.87        99\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# get predictions for the verification sample and generate a classification_report\n",
        "valid_pred = [categories.index(process.extractOne(pred, categories)[0]) for pred in y_pred_val]\n",
        "print(classification_report(dataset['validation']['category'], valid_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhcXBsUcad3D"
      },
      "outputs": [],
      "source": [
        "# do the same for the test sample\n",
        "y_pred_test = list(map(lambda x: llm(x)[0]['generated_text'], dataset['test']['message_for_llm']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = [categories.index(process.extractOne(pred, categories)[0]) for pred in y_pred_test]\n",
        "print(classification_report(dataset['test']['category'], test_pred))"
      ],
      "metadata": {
        "id": "x-lpYGdgcqvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383249b4-c081-4eb6-fb57-2a1b47e91bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.47      0.60        19\n",
            "           1       0.79      0.88      0.83        17\n",
            "           2       0.77      0.77      0.77        22\n",
            "           3       0.85      0.93      0.89        30\n",
            "           4       0.82      0.98      0.89        51\n",
            "           5       0.91      0.80      0.85        25\n",
            "           6       0.89      0.80      0.84        40\n",
            "\n",
            "    accuracy                           0.84       204\n",
            "   macro avg       0.84      0.81      0.81       204\n",
            "weighted avg       0.84      0.84      0.83       204\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIdte7tHVBNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4551e57a-e777-42ab-e367-a0e28c2d784f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "909.0742793083191\n"
          ]
        }
      ],
      "source": [
        "# measure the time to get one prediction and predictions for the whole dataset\n",
        "end_time = time.time()\n",
        "print(end_time - start_time)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}